{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmaamar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py:204: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H1, 2019-06-21 04:30:03,432     INFO  character-level CNN with BN and scheduled learning rate\n",
      "\n",
      "    `Dos Santos, CÃ­cero Nogueira, and Maira Gatti. \"Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts.\" COLING. 2014.`\n",
      "\n",
      "\n",
      "\n",
      "        - inputs:\n",
      "\n",
      "            - onehot char vector (max word num in sentence, max char num in word, character size)\n",
      "\n",
      "            - embedded vector of word (max word num in sentence, embedded dimension)\n",
      "\n",
      "        - network\n",
      "\n",
      "            - word -(CNN)-> feature by word (w)\n",
      "\n",
      "            - char -(CNN)-> char embedded vector for each word -(CNN)-> feature by char (c)\n",
      "\n",
      "            [c, w] -> CNN + max pool over feature -> FC -> output\n",
      "\n",
      "    \n",
      "H1, 2019-06-21 04:30:03,434     INFO train: epoch (500), size (41), iteration in an epoch (0), batch size(100)\n",
      "H1, 2019-06-21 04:30:03,435     INFO validation: size (6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmaamar/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/wmaamar/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/python_projects/vldb_submission/code/charcnn_text_classification_project_1/train_char_cnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m     train(model=model_instance[\"model\"], input_format=model_instance[\"input_format\"],\n\u001b[1;32m    152\u001b[0m           \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_feeder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m           test=False)\n\u001b[0m",
      "\u001b[0;32m~/python_projects/vldb_submission/code/charcnn_text_classification_project_1/train_char_cnn.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, feeder, input_format, save_path, lr_decay, test)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         logger.info(\"epoch %i: acc %0.3f, loss %0.3f, train acc %0.3f, train loss %0.3f\"\n\u001b[0;32m---> 66\u001b[0;31m                     % (_e, _result_full[3], _result_full[2], _result_full[1], _result_full[0]))\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_e\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "%run train_char_cnn.py --train_path ../../data/datasets/sentiment_analysis/stanford_paraphrases_sentiment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-e [EPOCH]] [-b [BATCH]] [-l [LR]]\n",
      "                             [-c [CLIP]] [-k [KEEP]] [-n [NORM]]\n",
      "                             [-d [DECAY_LR]]\n",
      "                             [model]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tfimport os\n",
    "\n",
    "import logging\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sequence_modeling\n",
    "\n",
    "import gensim\n",
    "\n",
    "from data.util import data_set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch, model, feeder, input_format, save_path=\"./\", lr_decay=1.0, test=False):\n",
    "\n",
    "    \"\"\" Train model based on mini-batch of input data.\n",
    "\n",
    "\n",
    "\n",
    "    :param model: model instance\n",
    "\n",
    "    :param str save_path: Path to save\n",
    "\n",
    "    :param int epoch:\n",
    "\n",
    "    :param feeder: Feeding data.\n",
    "\n",
    "    :param input_format: (optional) Input data format for `model`. For instance\n",
    "\n",
    "            def input_format(model, x):\n",
    "\n",
    "                return {model.x_char: x[0], model.x_word: x[1]}\n",
    "\n",
    "        This example is used when char and word vector is fed through the `feeder`. This function has to return dict.\n",
    "\n",
    "        By default, def input_format(model, x): return {model.x: x}\n",
    "\n",
    "    :param float lr_decay: learning rate will be divided by lr_decay each epoch\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # logger\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    logger = create_log(\"%s/log\" % save_path)\n",
    "\n",
    "    logger.info(model.__doc__)\n",
    "\n",
    "    logger.info(\"train: epoch (%i), size (%i), iteration in an epoch (%i), batch size(%i)\"\n",
    "\n",
    "                % (epoch, feeder.n, feeder.iterator_length, feeder.batch_size))\n",
    "\n",
    "    logger.info(\"validation: size (%i)\" % feeder.n_valid)\n",
    "\n",
    "    result = []\n",
    "\n",
    "\n",
    "\n",
    "    # Initializing the tensor flow variables\n",
    "\n",
    "    tf_writer = tf.summary.FileWriter(save_path, model.sess.graph)\n",
    "\n",
    "    model.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for _e in range(epoch):\n",
    "\n",
    "\n",
    "\n",
    "        _result = []\n",
    "\n",
    "        for _b in range(feeder.iterator_length):  # Train\n",
    "\n",
    "            _x, _y = feeder.next()\n",
    "\n",
    "            feed_dict = input_format(model, _x)\n",
    "\n",
    "            feed_dict[model.y] = _y\n",
    "\n",
    "            feed_dict[model.is_train] = True\n",
    "\n",
    "            if lr_decay != 1.0:\n",
    "\n",
    "                feed_dict[model.lr_decay] = lr_decay ** (np.ceil(_e / 100) - 1)  # every 100 epoch, (decay) ** lr_index\n",
    "\n",
    "            loss, acc, _ = model.sess.run([model.loss, model.accuracy, model.train], feed_dict=feed_dict)\n",
    "\n",
    "            _result.append([loss, acc])\n",
    "\n",
    "            if test:\n",
    "\n",
    "                logger.info(\"iter %i: acc %0.3f, loss %0.3f\" % (_b, loss, acc))\n",
    "\n",
    "\n",
    "\n",
    "        _result_valid = []\n",
    "\n",
    "        for _b in range(feeder.iterator_length_valid):  # Test\n",
    "\n",
    "            _x, _y = feeder.next_valid()\n",
    "\n",
    "            feed_dict = input_format(model, _x)\n",
    "\n",
    "            feed_dict[model.y] = _y\n",
    "\n",
    "            summary, loss, acc = model.sess.run([model.summary, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "            _result_valid.append([loss, acc])\n",
    "\n",
    "            tf_writer.add_summary(summary, int(_e))\n",
    "\n",
    "\n",
    "\n",
    "        _result_full = np.append(np.mean(_result, 0), np.mean(_result_valid, 0))\n",
    "\n",
    "        logger.info(\"epoch %i: acc %0.3f, loss %0.3f, train acc %0.3f, train loss %0.3f\"\n",
    "\n",
    "                    % (_e, _result_full[3], _result_full[2], _result_full[1], _result_full[0]))\n",
    "\n",
    "        result.append(_result_full)\n",
    "\n",
    "        if _e % 50 == 0:\n",
    "\n",
    "            model.saver.save(model.sess, \"%s/progress-%i-model.ckpt\" % (save_path, _e))\n",
    "\n",
    "            np.savez(\"%s/progress-%i-acc.npz\" % (save_path, _e), loss=np.array(result))\n",
    "\n",
    "    model.saver.save(model.sess, \"%s/model.ckpt\" % save_path)\n",
    "\n",
    "    feeder.finalize()  # destructor of feeder\n",
    "\n",
    "    np.savez(\"%s/statistics.npz\" % save_path, loss=np.array(result))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_log(name):\n",
    "\n",
    "    \"\"\"Logging.\"\"\"\n",
    "\n",
    "    if os.path.exists(name):\n",
    "\n",
    "        os.remove(name)\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    # handler for logger file\n",
    "\n",
    "    handler1 = logging.FileHandler(name)\n",
    "\n",
    "    handler1.setFormatter(logging.Formatter(\"H1, %(asctime)s %(levelname)8s %(message)s\"))\n",
    "\n",
    "    # handler for standard output\n",
    "\n",
    "    handler2 = logging.StreamHandler()\n",
    "\n",
    "    handler2.setFormatter(logging.Formatter(\"H1, %(asctime)s %(levelname)8s %(message)s\"))\n",
    "\n",
    "    logger.addHandler(handler1)\n",
    "\n",
    "    logger.addHandler(handler2)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_options(parser):\n",
    "\n",
    "    share_param = {'nargs': '?', 'action': 'store', 'const': None, 'choices': None, 'metavar': None}\n",
    "\n",
    "    parser.add_argument('model', help='Name of model to use. (default: cnn_char)',\n",
    "\n",
    "                        default='cnn_char', type=str, **share_param)\n",
    "\n",
    "    parser.add_argument('-e', '--epoch', help='Epoch number. (default: 500)',\n",
    "\n",
    "                        default=500, type=int, **share_param)\n",
    "\n",
    "    parser.add_argument('-b', '--batch', help='Batch size. (default: 100)',\n",
    "\n",
    "                        default=100, type=int, **share_param)\n",
    "\n",
    "    parser.add_argument('-l', '--lr', help='Learning rate. (default: 0.0001)',\n",
    "\n",
    "                        default=0.0001, type=float, **share_param)\n",
    "\n",
    "    parser.add_argument('-c', '--clip', help='Gradient clipping. (default: None)',\n",
    "\n",
    "                        default=None, type=float, **share_param)\n",
    "\n",
    "    parser.add_argument('-k', '--keep', help='Keep rate for Dropout. (default: 1.0)',\n",
    "\n",
    "                        default=1.0, type=float, **share_param)\n",
    "\n",
    "    parser.add_argument('-n', '--norm', help='Decay for batch normalization. if batch is 100, 0.95 (default: None)',\n",
    "\n",
    "                        default=None, type=float, **share_param)\n",
    "\n",
    "    parser.add_argument('-d', '--decay_lr', help='Decay index for learning rate (default: 1.0)',\n",
    "\n",
    "                        default=1.0, type=float, **share_param)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Ignore warning message by tensor flow\n",
    "\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "    _parser = argparse.ArgumentParser(description='This script is ...', formatter_class=argparse.RawTextHelpFormatter)\n",
    "\n",
    "    args = get_options(_parser)\n",
    "\n",
    "\n",
    "\n",
    "    # save path\n",
    "\n",
    "    path = \"./log/%s/l%0.6f_e%i_b%i\" % (args.model, args.lr, args.epoch, args.batch)\n",
    "\n",
    "    if args.decay_lr != 1.0:  # learning rate decaying\n",
    "\n",
    "        path += \"_d%0.2f\" % args.decay_lr\n",
    "\n",
    "    if args.clip is not None:  # gradient clipping\n",
    "\n",
    "        path += \"_c%0.2f\" % args.clip\n",
    "\n",
    "    if args.norm is not None:  # batch normalization\n",
    "\n",
    "        path += \"_n%0.3f\" % args.norm\n",
    "\n",
    "    if args.keep != 1.0:  # dropout\n",
    "\n",
    "        path += \"_k%0.2f\" % args.keep\n",
    "\n",
    "\n",
    "\n",
    "    # word2vec\n",
    "\n",
    "    embedding_model = gensim.models.KeyedVectors.load_word2vec_format(\"./data/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "\n",
    "\n",
    "    # load data\n",
    "\n",
    "    data = data_set()\n",
    "\n",
    "\n",
    "\n",
    "    # load model\n",
    "\n",
    "    model_instance = sequence_modeling.get_model_instance(model_name=args.model,\n",
    "\n",
    "                                                          embedding_model=embedding_model,\n",
    "\n",
    "                                                          learning_rate=args.lr,\n",
    "\n",
    "                                                          gradient_clip=args.clip,\n",
    "\n",
    "                                                          batch_norm=args.norm,\n",
    "\n",
    "                                                          keep_prob=args.keep)\n",
    "\n",
    "\n",
    "\n",
    "    # train\n",
    "\n",
    "    data_feeder = sequence_modeling.BatchFeeder(data[\"sentence\"], data[\"label\"], batch_size=args.batch,\n",
    "\n",
    "                                                validation=0.05, process=model_instance[\"processing\"])\n",
    "\n",
    "    train(model=model_instance[\"model\"], input_format=model_instance[\"input_format\"],\n",
    "\n",
    "          epoch=args.epoch, feeder=data_feeder, save_path=path, lr_decay=args.decay_lr,\n",
    "\n",
    "          test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e5622ca3a746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0m_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'This script is ...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawTextHelpFormatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e5622ca3a746>\u001b[0m in \u001b[0;36mget_options\u001b[0;34m(parser)\u001b[0m\n\u001b[1;32m    217\u001b[0m                         default=1.0, type=float, **share_param)\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'output_1' with dtype float and shape [?]\n\t [[node output_1 (defined at /home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py:188) ]]\n\nCaused by op 'output_1', defined at:\n  File \"/home/wmaamar/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-3f650fe32e8a>\", line 1, in <module>\n    get_ipython().run_line_magic('run', 'train_char_cnn.py --train_path ../../data/datasets/sentiment_analysis/stanford_paraphrases_sentiment.csv')\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-60>\", line 2, in run\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 775, in run\n    run()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 761, in run\n    exit_ignore=exit_ignore)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2527, in safe_execfile\n    self.compile if shell_futures else None)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/utils/py3compat.py\", line 188, in execfile\n    exec(compiler(f.read(), fname, 'exec'), glob, loc)\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/train_char_cnn.py\", line 145, in <module>\n    keep_prob=args.keep)\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/__init__.py\", line 57, in get_model_instance\n    batch_norm=batch_norm, keep_prob=keep_prob)\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py\", line 146, in __init__\n    self._create_network()\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py\", line 188, in _create_network\n    self.y = tf.placeholder(tf.float32, [None], name=\"output\")\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'output_1' with dtype float and shape [?]\n\t [[node output_1 (defined at /home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py:188) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'output_1' with dtype float and shape [?]\n\t [[{{node output_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/utils/py3compat.py\u001b[0m in \u001b[0;36mexecfile\u001b[0;34m(fname, glob, loc, compiler)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;31m# Refactor print statements in doctests.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_projects/vldb_submission/code/charcnn_text_classification_project_1/train_char_cnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m     train(model=model_instance[\"model\"], input_format=model_instance[\"input_format\"],\n\u001b[1;32m    151\u001b[0m           \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_feeder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m           test=False)\n\u001b[0m",
      "\u001b[0;32m~/python_projects/vldb_submission/code/charcnn_text_classification_project_1/train_char_cnn.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, feeder, input_format, save_path, lr_decay, test)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0m_result_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mtf_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'output_1' with dtype float and shape [?]\n\t [[node output_1 (defined at /home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py:188) ]]\n\nCaused by op 'output_1', defined at:\n  File \"/home/wmaamar/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-3f650fe32e8a>\", line 1, in <module>\n    get_ipython().run_line_magic('run', 'train_char_cnn.py --train_path ../../data/datasets/sentiment_analysis/stanford_paraphrases_sentiment.csv')\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-60>\", line 2, in run\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 775, in run\n    run()\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 761, in run\n    exit_ignore=exit_ignore)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2527, in safe_execfile\n    self.compile if shell_futures else None)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/IPython/utils/py3compat.py\", line 188, in execfile\n    exec(compiler(f.read(), fname, 'exec'), glob, loc)\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/train_char_cnn.py\", line 145, in <module>\n    keep_prob=args.keep)\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/__init__.py\", line 57, in get_model_instance\n    batch_norm=batch_norm, keep_prob=keep_prob)\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py\", line 146, in __init__\n    self._create_network()\n  File \"/home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py\", line 188, in _create_network\n    self.y = tf.placeholder(tf.float32, [None], name=\"output\")\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/wmaamar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'output_1' with dtype float and shape [?]\n\t [[node output_1 (defined at /home/wmaamar/python_projects/vldb_submission/code/charcnn_text_classification_project_1/sequence_modeling/model/cnn_char.py:188) ]]\n"
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
